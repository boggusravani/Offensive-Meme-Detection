{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords, words\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from textblob import TextBlob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6830 entries, 0 to 6991\n",
      "Data columns (total 5 columns):\n",
      "Unnamed: 0        6830 non-null int64\n",
      "image_name        6830 non-null object\n",
      "text_ocr          6830 non-null object\n",
      "text_corrected    6830 non-null object\n",
      "target            6830 non-null object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 320.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notoffensive        4058\n",
       "slightoffensive     2157\n",
       "hatefuloffensive     469\n",
       "veryoffensive        146\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"target\", data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['message'] = df['text_corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet = []\n",
    "Labels = []\n",
    "\n",
    "for row in df[\"message\"]:\n",
    "    #tokenize words\n",
    "    words = word_tokenize(row)\n",
    "    #remove punctuations\n",
    "    clean_words = [word.lower() for word in words if word not in set(string.punctuation)]\n",
    "    #remove stop words\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    characters_to_remove = [\"''\",'``',\"rt\",\"https\",\"’\",\"“\",\"”\",\"\\u200b\",\"--\",\"n't\",\"'s\",\"...\",\"//t.c\" ]\n",
    "    clean_words = [word for word in clean_words if word not in english_stops]\n",
    "    clean_words = [word for word in clean_words if word not in set(characters_to_remove)]\n",
    "    #Lematise words\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma_list = [wordnet_lemmatizer.lemmatize(word) for word in clean_words]\n",
    "    Tweet.append(lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# label_encoder object knows\n",
    "# how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Encode labels in column 'species'.\n",
    "df['class']= label_encoder.fit_transform(df['target'])\n",
    "\n",
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['message']\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Feature With CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cv, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(X_train, y_train) \n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "val1 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5080527086383602"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "clf1 = AdaBoostClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[('ab', clf1), ('rf', clf2)], voting='soft')\n",
    "eclf1.fit(X_train,y_train)\n",
    "\n",
    "y_pred = eclf1.predict(X_test)\n",
    "\n",
    "val2 = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978038067349927"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "#from tensorflow.keras.layers import LSTM\n",
    "\n",
    "\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting parameters which will be used throughout\n",
    "num_words = 15000  # Parameter indicating the number of words we'll put in the dictionary\n",
    "val_size = 1000  # Size of the validation set\n",
    "epochs = 20  # Number of epochs we usually start to train with\n",
    "batch_size = 16  # Size of the batches used in the mini-batch gradient descent\n",
    "#Taking only two columns since it's a sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets conssits of every document as an array of tokenized words which are later appended to docs \n",
    "tweets=[word_tokenize(tweet) for tweet in df['message']]\n",
    "docs=[]\n",
    "for j in range(0,len(tweets)):\n",
    "    docs.append(tweets[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stops included both the stopwords and punctuations\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "not_list = [\"n't\", \"not\", \"no\"]\n",
    "stops.update(punctuations)\n",
    "stops.update(not_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the simple pos(part of speech) tag\n",
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the pos tag for a word\n",
    "from nltk import pos_tag\n",
    "# now we are going to clean our data \n",
    "# we will remove stopwords and punctuations and lemmatize each document\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def clean(words):\n",
    "    output=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stops or word.lower() in not_list:\n",
    "            pos=pos_tag(word)\n",
    "            clean_word=lemmatizer.lemmatize(word,pos=get_simple_pos(pos[0][1]))\n",
    "            output.append(clean_word.lower())\n",
    "    str1=\" \".join(output).encode('utf-8')        \n",
    "    return str1\n",
    "#docs=[ clean(doc) for doc in docs]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>notoffensive</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>notoffensive</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>notoffensive</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>notoffensive</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>slightoffensive</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_name  \\\n",
       "0           0   image_1.jpg   \n",
       "1           1  image_2.jpeg   \n",
       "2           2   image_3.JPG   \n",
       "3           3   image_4.png   \n",
       "4           4   image_5.png   \n",
       "\n",
       "                                            text_ocr  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3              10 Year Challenge - Sweet Dee Edition   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                      text_corrected           target  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...     notoffensive   \n",
       "1  The best of #10 YearChallenge! Completed in le...     notoffensive   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...     notoffensive   \n",
       "3              10 Year Challenge - Sweet Dee Edition     notoffensive   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...  slightoffensive   \n",
       "\n",
       "                                             message  class  \n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...      1  \n",
       "1  The best of #10 YearChallenge! Completed in le...      1  \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...      1  \n",
       "3              10 Year Challenge - Sweet Dee Edition      1  \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking variables to be used for train test split as X,y\n",
    "X,Y=df['message'].values,pd.get_dummies(df['class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted tokenizer on 6830 documents\n",
      "15000 words in dictionary\n",
      "Top 5 most common words are: [('the', 3112), ('you', 2459), ('a', 2066), ('i', 2012), ('to', 1845)]\n"
     ]
    }
   ],
   "source": [
    "#using tokenizers to create the tokens having no of words=15000(num_words)\n",
    "tk = Tokenizer(num_words=num_words,\n",
    "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \")\n",
    "#Complete data is tokenized to vectors and padding is done using zeros to match its length to the largest text in the dataset.\n",
    "tk.fit_on_texts(X)\n",
    "X = tk.texts_to_sequences(X)\n",
    "X = pad_sequences(X)\n",
    "#print(X[:2])\n",
    "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
    "print('{} words in dictionary'.format(tk.num_words))\n",
    "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tk,open('transform.pkl','wb'))\n",
    "#files.download('transform2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, LSTM, GRU\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128 #dimension of the word embedding vector for each word in a sequence \n",
    "lstm_out = 196  #no of lstm layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "#Adding dropout\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Adding a regularized dense layer\n",
    "model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 192, 128)          1920000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 2,181,236\n",
      "Trainable params: 2,181,236\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 194s 560ms/step - loss: 1.0313 - accuracy: 0.5917 - val_loss: 0.9781 - val_accuracy: 0.5754\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 213s 622ms/step - loss: 0.9761 - accuracy: 0.5988 - val_loss: 0.9933 - val_accuracy: 0.5754\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 218s 638ms/step - loss: 0.8488 - accuracy: 0.6288 - val_loss: 1.0894 - val_accuracy: 0.4985\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 217s 634ms/step - loss: 0.6471 - accuracy: 0.7399 - val_loss: 1.2805 - val_accuracy: 0.5110\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 216s 633ms/step - loss: 0.4762 - accuracy: 0.8318 - val_loss: 1.5360 - val_accuracy: 0.4780\n"
     ]
    }
   ],
   "source": [
    "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
    "history1 = model.fit(X_train, Y_train, epochs = 5, batch_size=16,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val3 = history1.history['val_accuracy'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 192, 128)          1920000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 196)               63700     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                6304      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 1,990,136\n",
      "Trainable params: 1,990,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128 #dimension of the word embedding vector for each word in a sequence \n",
    "lstm_out = 196  #no of lstm layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, embed_dim,input_length = X_train.shape[1]))\n",
    "#Adding dropout\n",
    "model.add(SimpleRNN(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "#Adding a regularized dense layer\n",
    "model.add(layers.Dense(32,kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "342/342 [==============================] - 45s 128ms/step - loss: 1.1003 - accuracy: 0.5719 - val_loss: 1.0186 - val_accuracy: 0.5754\n",
      "Epoch 2/5\n",
      "342/342 [==============================] - 43s 125ms/step - loss: 1.0275 - accuracy: 0.5986 - val_loss: 1.0033 - val_accuracy: 0.5754\n",
      "Epoch 3/5\n",
      "342/342 [==============================] - 43s 126ms/step - loss: 0.9977 - accuracy: 0.5990 - val_loss: 1.0010 - val_accuracy: 0.5754\n",
      "Epoch 4/5\n",
      "342/342 [==============================] - 43s 126ms/step - loss: 0.9560 - accuracy: 0.5985 - val_loss: 1.0229 - val_accuracy: 0.5754\n",
      "Epoch 5/5\n",
      "342/342 [==============================] - 43s 126ms/step - loss: 0.8789 - accuracy: 0.6076 - val_loss: 1.0970 - val_accuracy: 0.5476\n"
     ]
    }
   ],
   "source": [
    "#model trained on the training data and taking validation data into account to avoid overfitting for 4 epochs \n",
    "history2 = model.fit(X_train, Y_train, epochs = 5, batch_size=16,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "val4 = history2.history['val_accuracy'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model_hy=tf.keras.Sequential()\n",
    "\n",
    "model_hy.add(tf.keras.layers.Input(shape=[100]))\n",
    "model_hy.add(tf.keras.layers.Embedding(num_words,embed_dim,input_length=X_train.shape[1]))    \n",
    "\n",
    "model_hy.add(tf.keras.layers.LSTM(200, return_sequences=True))\n",
    "model_hy.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_hy.add(tf.keras.layers.LSTM(200,return_sequences=True))\n",
    "model_hy.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_hy.add(tf.keras.layers.GRU(200))\n",
    "model_hy.add(tf.keras.layers.Dropout(0.5))\n",
    "          \n",
    "model_hy.add(tf.keras.layers.Dense(256))\n",
    "model_hy.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model_hy.add(tf.keras.layers.Dense(4,activation='sigmoid')) #output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 128)          1920000   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 200)          263200    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100, 200)          320800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 200)          0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 200)               241200    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               51456     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 2,797,684\n",
      "Trainable params: 2,797,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_hy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hy.compile(loss='categorical_crossentropy',optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 192).\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.9884 - accuracy: 0.5659WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 192).\n",
      "171/171 [==============================] - 111s 634ms/step - loss: 0.9884 - accuracy: 0.5659 - val_loss: 0.9461 - val_accuracy: 0.5754\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 110s 642ms/step - loss: 0.9060 - accuracy: 0.5944 - val_loss: 0.6650 - val_accuracy: 0.7291\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 109s 641ms/step - loss: 0.5743 - accuracy: 0.7709 - val_loss: 0.2245 - val_accuracy: 0.9209\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 110s 643ms/step - loss: 0.2886 - accuracy: 0.8953 - val_loss: 0.1361 - val_accuracy: 0.9597\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 110s 646ms/step - loss: 0.1657 - accuracy: 0.9466 - val_loss: 0.0881 - val_accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "history3 = model_hy.fit(X_train, Y_train, epochs = 5, batch_size=2,validation_data=(X_test, Y_test),verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val5 = history3.history['val_accuracy'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['DT','Voting','LSTM','RNN','LSTM+GRU']\n",
    "y = [val1,val2,val3,val4,val5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.barh(x,y, color='brown')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.sav']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "filename = 'model.sav'\n",
    "joblib.dump(eclf1, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open(\"model.pkl\", 'rb'))\n",
    "\n",
    "model = joblib.load('model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easyocr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"images/images/image_133.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[[72, 8], [392, 8], [392, 80], [72, 80]], 'WITHOUT ME'],\n",
       " [[[24, 356], [436, 356], [436, 427], [24, 427]], 'IT\"S JUST AWESO']]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(IMAGE_PATH,paragraph=\"False\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = result[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT\"S JUST AWESO\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    var2 = result[1][1]\n",
    "    print(var2)\n",
    "except IndexError:\n",
    "    var2 = '!'\n",
    "    print(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "var3 = \" \".join([var1, var2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WITHOUT ME IT\"S JUST AWESO'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [var3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "vect = cv.transform(data).toarray()\n",
    "my_prediction = model.predict(vect)\n",
    "        \n",
    "print(my_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
